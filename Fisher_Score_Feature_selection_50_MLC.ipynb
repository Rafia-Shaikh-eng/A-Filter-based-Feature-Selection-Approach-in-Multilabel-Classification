{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafia-Shaikh-eng/A-Filter-based-Feature-Selection-Approach-in-Multilabel-Classification/blob/main/Fisher_Score_Feature_selection_50_MLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdG1WwzQe26j"
      },
      "source": [
        "importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE70ALC9f3Ii"
      },
      "outputs": [],
      "source": [
        "# if the scikit-multilearn not installed run this cell\n",
        "!pip install scikit-multilearn\n",
        "# most of the datasets in Weka Arff format for this installed this library\n",
        "!pip install arff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEk8PbRke7t_"
      },
      "source": [
        "Created 03 arrays of each measuring metrics for 03 classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJucbp86f9vF"
      },
      "outputs": [],
      "source": [
        "#03 classifiers hamming loss list\n",
        "hamming_loss_MLTSVM=[]\n",
        "hamming_loss_MLKNN=[]\n",
        "hamming_loss_BRKNNa=[]\n",
        "#03 classifier accuracy list\n",
        "accuracy_MLTSVM=[]\n",
        "accuracy_MLKNN=[]\n",
        "accuracy_BRKNNa=[]\n",
        "#03 classifier precision list\n",
        "precision_MLTSVM=[]\n",
        "precision_MLKNN=[]\n",
        "precision_BRKNNa=[]\n",
        "#03 classifier recall list\n",
        "recall_MLTSVM=[]\n",
        "recall_MLKNN=[]\n",
        "recall_BRKNNa=[]\n",
        "#03 classifier f1 measure list\n",
        "f1_measure_MLTSVM=[]\n",
        "f1_measure_MLKNN=[]\n",
        "f1_measure_BRKNNa=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40EXuk8PgEWh"
      },
      "source": [
        "# 01 Medical Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QYSpg5gOSI",
        "outputId": "18c2d6f0-7e6c-4ae5-8277-325348da93a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(978, 1449) (978, 45)\n",
            "Coverted into Dataframe\n",
            "(978, 1449) (978, 45)\n"
          ]
        }
      ],
      "source": [
        "#Load Medical Dataset\n",
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('medical', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x1=x.todense()\n",
        "y1=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x1=pd.DataFrame(x1)\n",
        "y1=pd.DataFrame(y1)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x1.shape,y1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w28ucdQO9NXA",
        "outputId": "1d663071-4885-44de-a538-3a8ad81bcd19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(x1.shape[1]*0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVf2goSUgHDN"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hruMGmkl9NXA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "def calculate_fisher_score(X, Y):\n",
        "    fisher_scores, _ = f_classif(X, Y)\n",
        "    return fisher_scores\n",
        "\n",
        "def select_top_K_features(scores, K):\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    return sorted_indices[:K]\n",
        "\n",
        "def select_features(X, Y, K,p):\n",
        "    selected_features = set()\n",
        "    MI = {}  # Create an empty dictionary\n",
        "\n",
        "    # Calculate Fisher's scores for each feature associated with each label\n",
        "    for label in Y.columns:\n",
        "        MI[label] = calculate_fisher_score(X, Y[label])\n",
        "    # Select top K features for each label\n",
        "    for label in MI.keys():\n",
        "        topK = select_top_K_features(MI[label], K)\n",
        "        MI[label] = topK\n",
        "    # Count occurrences of selected features\n",
        "    feature_counts = {}\n",
        "    for label in MI.keys():\n",
        "        for feature in MI[label]:\n",
        "            if feature in feature_counts:\n",
        "                feature_counts[feature] += 1\n",
        "            else:\n",
        "                feature_counts[feature] = 1\n",
        "\n",
        "    # Select features based on the aggregated counts\n",
        "    for feature, count in feature_counts.items():\n",
        "        if count >= int(len((Y.columns))*p):  # Adjust this condition as needed\n",
        "            selected_features.add(feature)\n",
        "\n",
        "    return selected_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugGe-RQ69NXB"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x1, y1, K=int((x1.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x1.columns):\n",
        "    if i not in selected_features:\n",
        "        x1 = x1.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIxuiJ3Q9NXC",
        "outputId": "bc4c6df4-2ade-4b50-8699-7a99fd78f816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(978, 1449)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYNehoigr6n"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U8kN0z8gizm",
        "outputId": "646c126a-0fd1-4dff-85a2-3d12e23c8d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(687, 1449) (291, 1449) (687, 45) (291, 45)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x1 = s.csr_matrix(x1)\n",
        "y1 = s.csr_matrix(y1)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x1_train, y1_train, x1_test, y1_test = iterative_train_test_split(x1, y1, test_size = 0.3)\n",
        "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCLP9vog4NE"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNkimd9guHp"
      },
      "outputs": [],
      "source": [
        "#MLTSVM\n",
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(max_iteration=1000,c_k=2**-6)\n",
        "# train\n",
        "classifier1.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLTSVM1_predictions = classifier1.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YUC40jeg6Ca"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCT3Jbj1g7L2"
      },
      "outputs": [],
      "source": [
        "#MLKNN\n",
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for medical dataset it has 45 labels.\n",
        "classifier2 = MLkNN(k=45)\n",
        "# train\n",
        "classifier2.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLKNN1_predictions = classifier2.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1w6zZiEg7nQ"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_tHDGxjg8nK"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=45)\n",
        "# train\n",
        "classifier3.fit(x1_train, y1_train)\n",
        "# predict\n",
        "BR1_predictions = classifier3.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqkcSY2whDb9"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6FQQ9MxhFX-"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynx5rIJIhHai",
        "outputId": "1905c0e9-ee46-45f5-a4f9-816457ab83e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (291, 45)\n",
            "MLKNN  ->  (291, 45)\n",
            "BRKNNa ->  (291, 45)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.02\n",
            "BRKNNa ->  0.02\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.48\n",
            "MLKNN  ->  0.46\n",
            "BRKNNa ->  0.26\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.75\n",
            "MLKNN ->  0.87\n",
            "BRKNNa ->  0.82\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.66\n",
            "MLTSVM ->  0.53\n",
            "MLTSVM ->  0.3\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.7\n",
            "MLTSVM ->  0.66\n",
            "MLTSVM ->  0.44\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM1_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN1_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR1_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcWI-UChJwd"
      },
      "source": [
        "# 02 Enron Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGr-CkgPhPwP",
        "outputId": "2dbe8d04-14dd-4069-f926-b8edf35cf9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(1702, 1001) (1702, 53)\n",
            "Coverted into Dataframe\n",
            "(1702, 1001) (1702, 53)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('enron', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x2=x.todense()\n",
        "y2=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x2=pd.DataFrame(x2)\n",
        "y2=pd.DataFrame(y2)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x2.shape,y2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXT4vqmG9NXH"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3F1mrn49NXH"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x2, y2, K=int((x2.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x2.columns):\n",
        "    if i not in selected_features:\n",
        "        x2 = x2.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqvxff7i9NXI",
        "outputId": "d07f2f72-493d-4ffc-d5b6-2a19139d3906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1702, 568)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geaCWnlShd8V"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy72vS1uhdbF",
        "outputId": "aa75d568-623e-429d-c023-e6746f3e8200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1190, 568) (512, 568) (1190, 53) (512, 53)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x2 = s.csr_matrix(x2)\n",
        "y2 = s.csr_matrix(y2)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x2_train, y2_train, x2_test, y2_test = iterative_train_test_split(x2, y2, test_size = 0.3)\n",
        "print(x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UkG4qIhmA0"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQrV6hoHhnOl"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x2_train, y2_train)\n",
        "# predict\n",
        "MLTSVM2_predictions = classifier1.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4mQhAYhnu4"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9MCgnWXho55"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for enron dataset it has 53 labels.\n",
        "classifier2 = MLkNN(k=53)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x2_train, y2_train)\n",
        "\n",
        "# predict\n",
        "MLKNN2_predictions = classifier2.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q77FQROhquS"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd-XcJd3hrtL"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=53)\n",
        "# train\n",
        "classifier3.fit(x2_train, y2_train)\n",
        "# predict\n",
        "BR2_predictions = classifier3.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s0jw9zchuXy"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRnvbkdhw6l"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0inwYSohyl9",
        "outputId": "f7928fe3-d0d3-4a77-d5b5-054320ef4722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (512, 53)\n",
            "MLKNN  ->  (512, 53)\n",
            "BRKNNa ->  (512, 53)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.07\n",
            "MLKNN  ->  0.06\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.07\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.44\n",
            "MLKNN ->  0.63\n",
            "BRKNNa ->  0.61\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.42\n",
            "MLTSVM ->  0.28\n",
            "MLTSVM ->  0.11\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.43\n",
            "MLTSVM ->  0.39\n",
            "MLTSVM ->  0.18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM2_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN2_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR2_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2TXIFdh_nM"
      },
      "source": [
        "# 03 Scene Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMyBY_axh0sv",
        "outputId": "bc85eecc-5be7-478c-9b6d-e1e9d01e5ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scene:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(2407, 294) (2407, 6)\n",
            "Coverted into Dataframe\n",
            "(2407, 294) (2407, 6)\n"
          ]
        }
      ],
      "source": [
        "#from skmultilearn.dataset import load_dataset\n",
        "x3,y3, _, _ = load_dataset('scene', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x3.shape,y3.shape)\n",
        "#change to matrix\n",
        "x3=x3.todense()\n",
        "y3=y3.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x3=pd.DataFrame(x3)\n",
        "y3=pd.DataFrame(y3)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x3.shape,y3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEIT19NO9NXQ"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfvDhUb89NXQ"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x3, y3, K=int((x3.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x3.columns):\n",
        "    if i not in selected_features:\n",
        "        x3 = x3.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQldb_zO9NXQ",
        "outputId": "9f5a33ac-9947-4d6b-a7e0-c4959d2b856b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2407, 164)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5196nOiRQy"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y164N9r1iUqs",
        "outputId": "c2c3bcea-1086-4b2a-b9db-4781aa19cc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1685, 164) (722, 164) (1685, 6) (722, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x3 = s.csr_matrix(x3)\n",
        "y3 = s.csr_matrix(y3)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x3_train, y3_train, x3_test, y3_test = iterative_train_test_split(x3, y3, test_size = 0.3)\n",
        "print(x3_train.shape, x3_test.shape, y3_train.shape, y3_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7i-TEOYibPk"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spSuhLrwiclk"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x3_train, y3_train)\n",
        "# predict\n",
        "MLTSVM3_predictions = classifier1.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDkyhEm-idLA"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEOsqkozieMm"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for Scene dataset it has 6 labels.\n",
        "classifier2 = MLkNN(k=6)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x3_train, y3_train)\n",
        "\n",
        "# predict\n",
        "MLKNN3_predictions = classifier2.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soP4rbVxigYH"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8A69ylpiiIz"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=6)\n",
        "# train\n",
        "classifier3.fit(x3_train, y3_train)\n",
        "# predict\n",
        "BR3_predictions = classifier3.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8aWlmPiksm"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHQe8f4SinpS"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y3_test, MLKNN3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y3_test, BR3_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAbuGy2aiqRN",
        "outputId": "723d2977-09ab-44e7-91b1-0e92500f57cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (722, 6)\n",
            "MLKNN  ->  (722, 6)\n",
            "BRKNNa ->  (722, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.79\n",
            "MLKNN  ->  0.09\n",
            "BRKNNa ->  0.1\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.61\n",
            "BRKNNa ->  0.57\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.18\n",
            "MLKNN ->  0.8\n",
            "BRKNNa ->  0.83\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.64\n",
            "BRKNNa ->  0.58\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.31\n",
            "MLKNN ->  0.71\n",
            "BRKNNa ->  0.68\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM3_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN3_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR3_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ado0f34X9NXc"
      },
      "source": [
        "# 04 Emotions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqV169P79NXd",
        "outputId": "dcb9854a-3f1f-4a5f-b7b8-60a5c6cbee80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emotions:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(593, 72) (593, 6)\n",
            "Coverted into Dataframe\n",
            "(593, 72) (593, 6)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x4,y4, _, _ = load_dataset('emotions', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x4.shape,y4.shape)\n",
        "#change to matrix\n",
        "x4=x4.todense()\n",
        "y4=y4.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x4=pd.DataFrame(x4)\n",
        "y4=pd.DataFrame(y4)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x4.shape,y4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifWC0-HA9NXd"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bnpMob79NXe"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x4, y4, K=int((x4.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x4.columns):\n",
        "    if i not in selected_features:\n",
        "        x4 = x4.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI_GHozk9NXe",
        "outputId": "b05f2737-d48f-4ce3-852a-41bf2a53bff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(593, 40)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjYYSO8jGMe"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqplGSrwjNaw",
        "outputId": "b3432efb-2369-4af5-e3a0-b08ac09ed983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(416, 40) (177, 40) (416, 6) (177, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x4 = s.csr_matrix(x4)\n",
        "y4 = s.csr_matrix(y4)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x4_train, y4_train, x4_test, y4_test = iterative_train_test_split(x4, y4, test_size = 0.3)\n",
        "print(x4_train.shape, x4_test.shape, y4_train.shape, y4_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-uX-BIqjSMZ"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XklOJNDOjTVt"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x4_train, y4_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgzlva3xjT5y"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7SIU5KbjUyx"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x4_train, y4_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Yn9qcojXzz"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiUFTXdWjYxj"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x4_train, y4_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsQqXNfjbkI"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPZ71xjZjeBE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y4_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y4_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ1wjsf7jgGo",
        "outputId": "ec2bdc3c-6f8b-4828-d1ac-2669135cf20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (177, 6)\n",
            "MLKNN  ->  (177, 6)\n",
            "BRKNNa ->  (177, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.68\n",
            "MLKNN  ->  0.25\n",
            "BRKNNa ->  0.24\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.2\n",
            "BRKNNa ->  0.22\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.32\n",
            "MLKNN ->  0.64\n",
            "MLKNNa ->  0.66\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.44\n",
            "BRKNNa ->  0.5\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.48\n",
            "MLKNN ->  0.52\n",
            "BRKNNa ->  0.57\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f_yd4hsisv3"
      },
      "source": [
        "# 05 Genbase Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irsKBHGqi5gK",
        "outputId": "6f273469-d301-4fff-be18-d301b0bd83dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "genbase:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(662, 1186) (662, 27)\n",
            "Coverted into Dataframe\n",
            "(662, 1186) (662, 27)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x5,y5, _, _ = load_dataset('genbase', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x5.shape,y5.shape)\n",
        "#change to matrix\n",
        "x5=x5.todense()\n",
        "y5=y5.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x5=pd.DataFrame(x5)\n",
        "y5=pd.DataFrame(y5)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x5.shape,y5.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1IIQphM9NXl"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEWbObsg9NXl"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x5, y5, K=int((x5.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x5.columns):\n",
        "    if i not in selected_features:\n",
        "        x5 = x5.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h8eE_RN9NXm",
        "outputId": "4edf6f50-04fe-4561-db84-41937eabfdfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(662, 593)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsnZ1JZt9NXn"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3432efb-2369-4af5-e3a0-b08ac09ed983",
        "id": "zG7-hBvY9NXn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(463, 593) (199, 593) (463, 27) (199, 27)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x5 = s.csr_matrix(x5)\n",
        "y5 = s.csr_matrix(y5)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x5_train, y5_train, x5_test, y5_test = iterative_train_test_split(x5, y5, test_size = 0.3)\n",
        "print(x5_train.shape, x5_test.shape, y5_train.shape, y5_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSRd7HPw9NXo"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B4_eSgC9NXo"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x5_train, y5_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIBdrheC9NXq"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIAD4EUo9NXr"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x5_train, y5_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDAIQ31z9NXr"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzWTCSlE9NXs"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x5_train, y5_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap0dZVD_9NXs"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5GZE2T49NXt"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y5_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y5_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmkagq3c9NXt"
      },
      "outputs": [],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRgqpRadjiVz"
      },
      "source": [
        "# Results based on  EVALUATION MEASURES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bezV7sxyjsKJ"
      },
      "source": [
        "##Hamming Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXK9F7NXjrU5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dataset=['medical','enron','scene','gebase']\n",
        "hl=[]\n",
        "print(hamming_loss_MLKNN)\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,hamming_loss_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,hamming_loss_MLKNN, label='MLKNN',marker=\">\")\n",
        "ax.plot(dataset,hamming_loss_BRKNNa, label='BRKNNa',marker=\"*\")\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Hamming Loss')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-hamming loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTnz41Oxjv_P"
      },
      "source": [
        "##Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBO6ZTWvj0NS"
      },
      "outputs": [],
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,accuracy_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,accuracy_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,accuracy_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.savefig('chi-20-Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HCZyhktj1Dt"
      },
      "source": [
        "##Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bhk7Rtc1j4st"
      },
      "outputs": [],
      "source": [
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,precision_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,precision_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,precision_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro Precision')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-Precision')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBHu6gkj5nV"
      },
      "source": [
        "##Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tg4rjnKj6tB"
      },
      "outputs": [],
      "source": [
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,recall_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,recall_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,recall_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro Recall')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-Recall')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Dvi7SAj-iU"
      },
      "source": [
        "##F1 Measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfAzEw1kkAW-"
      },
      "outputs": [],
      "source": [
        "#F1 measure\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,f1_measure_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,f1_measure_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,f1_measure_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro F1 measure')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-f1 measure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILQqgkgtPktO"
      },
      "outputs": [],
      "source": [
        "#F1 measure\n",
        "fig, ax=plt.subplots()\n",
        "HL=[0.02, ]\n",
        "ax.plot(dataset,f1_measure_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,f1_measure_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,f1_measure_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro F1 measure')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-f1 measure')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}