{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafia-Shaikh-eng/A-Filter-based-Feature-Selection-Approach-in-Multilabel-Classification/blob/main/Fisher_Score_Feature_selection_50_MLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdG1WwzQe26j"
      },
      "source": [
        "importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE70ALC9f3Ii",
        "outputId": "f5feec8b-9da5-4c7b-bf08-e2db8743356c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-multilearn in c:\\users\\aashir\\anaconda3\\lib\\site-packages (0.2.0)\n",
            "Requirement already satisfied: arff in c:\\users\\aashir\\anaconda3\\lib\\site-packages (0.9)\n"
          ]
        }
      ],
      "source": [
        "# if the scikit-multilearn not installed run this cell\n",
        "!pip install scikit-multilearn\n",
        "# most of the datasets in Weka Arff format for this installed this library\n",
        "!pip install arff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEk8PbRke7t_"
      },
      "source": [
        "Created 03 arrays of each measuring metrics for 03 classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJucbp86f9vF"
      },
      "outputs": [],
      "source": [
        "#03 classifiers hamming loss list\n",
        "hamming_loss_MLTSVM=[]\n",
        "hamming_loss_MLKNN=[]\n",
        "hamming_loss_BRKNNa=[]\n",
        "#03 classifier accuracy list\n",
        "accuracy_MLTSVM=[]\n",
        "accuracy_MLKNN=[]\n",
        "accuracy_BRKNNa=[]\n",
        "#03 classifier precision list\n",
        "precision_MLTSVM=[]\n",
        "precision_MLKNN=[]\n",
        "precision_BRKNNa=[]\n",
        "#03 classifier recall list\n",
        "recall_MLTSVM=[]\n",
        "recall_MLKNN=[]\n",
        "recall_BRKNNa=[]\n",
        "#03 classifier f1 measure list\n",
        "f1_measure_MLTSVM=[]\n",
        "f1_measure_MLKNN=[]\n",
        "f1_measure_BRKNNa=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40EXuk8PgEWh"
      },
      "source": [
        "# 01 Medical Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QYSpg5gOSI",
        "outputId": "18c2d6f0-7e6c-4ae5-8277-325348da93a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(978, 1449) (978, 45)\n",
            "Coverted into Dataframe\n",
            "(978, 1449) (978, 45)\n"
          ]
        }
      ],
      "source": [
        "#Load Medical Dataset\n",
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('medical', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x1=x.todense()\n",
        "y1=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x1=pd.DataFrame(x1)\n",
        "y1=pd.DataFrame(y1)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x1.shape,y1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGGh6nCme2lf",
        "outputId": "81424aea-f0ca-4bbb-b142-ff4218c46c83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(x1.shape[1]*0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVf2goSUgHDN"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEN0rpWSe2lh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "def calculate_fisher_score(X, Y):\n",
        "    fisher_scores, _ = f_classif(X, Y)\n",
        "    return fisher_scores\n",
        "\n",
        "def select_top_K_features(scores, K):\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    return sorted_indices[:K]\n",
        "\n",
        "def select_features(X, Y, K,p):\n",
        "    selected_features = set()\n",
        "    MI = {}  # Create an empty dictionary\n",
        "\n",
        "    # Calculate Fisher's scores for each feature associated with each label\n",
        "    for label in Y.columns:\n",
        "        MI[label] = calculate_fisher_score(X, Y[label])\n",
        "    # Select top K features for each label\n",
        "    for label in MI.keys():\n",
        "        topK = select_top_K_features(MI[label], K)\n",
        "        MI[label] = topK\n",
        "    # Count occurrences of selected features\n",
        "    feature_counts = {}\n",
        "    for label in MI.keys():\n",
        "        for feature in MI[label]:\n",
        "            if feature in feature_counts:\n",
        "                feature_counts[feature] += 1\n",
        "            else:\n",
        "                feature_counts[feature] = 1\n",
        "\n",
        "    # Select features based on the aggregated counts\n",
        "    for feature, count in feature_counts.items():\n",
        "        if count >= int(len((Y.columns))*p):  # Adjust this condition as needed\n",
        "            selected_features.add(feature)\n",
        "\n",
        "    return selected_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FET9XvZte2lj",
        "outputId": "26f73e13-8aae-482a-a503-e75591e6fa29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x1, y1, K=int((x1.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x1.columns):\n",
        "    if i not in selected_features:\n",
        "        x1 = x1.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LAWF4Oie2lj",
        "outputId": "4add19ec-c495-4d5f-bb26-4d03acc3d782"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(978, 726)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYNehoigr6n"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U8kN0z8gizm",
        "outputId": "646c126a-0fd1-4dff-85a2-3d12e23c8d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(685, 726) (293, 726) (685, 45) (293, 45)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x1 = s.csr_matrix(x1)\n",
        "y1 = s.csr_matrix(y1)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x1_train, y1_train, x1_test, y1_test = iterative_train_test_split(x1, y1, test_size = 0.3)\n",
        "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCLP9vog4NE"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNkimd9guHp"
      },
      "outputs": [],
      "source": [
        "#MLTSVM\n",
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(max_iteration=1000,c_k=2**-6)\n",
        "# train\n",
        "classifier1.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLTSVM1_predictions = classifier1.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YUC40jeg6Ca"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCT3Jbj1g7L2",
        "outputId": "ba213806-ea78-4620-a16a-30b6419d6ca6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=45 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
          ]
        }
      ],
      "source": [
        "#MLKNN\n",
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for medical dataset it has 45 labels.\n",
        "classifier2 = MLkNN(k=45)\n",
        "# train\n",
        "classifier2.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLKNN1_predictions = classifier2.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1w6zZiEg7nQ"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_tHDGxjg8nK"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=45)\n",
        "# train\n",
        "classifier3.fit(x1_train, y1_train)\n",
        "# predict\n",
        "BR1_predictions = classifier3.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqkcSY2whDb9"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6FQQ9MxhFX-"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "# hamming_loss_MLTSVM.append(round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "# hamming_loss_MLKNN.append(round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "# hamming_loss_BRKNNa.append(round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "\n",
        "# #Accuracy\n",
        "# accuracy_MLTSVM.append(round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "# accuracy_MLKNN.append(round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "# accuracy_BRKNNa.append(round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "# f1_measure_MLTSVM.append(round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_MLKNN.append(round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_BRKNNa.append(round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynx5rIJIhHai",
        "outputId": "1905c0e9-ee46-45f5-a4f9-816457ab83e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.76\n",
            "MLKNN ->  0.84\n",
            "BRKNNa ->  0.81\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.68\n",
            "MLTSVM ->  0.49\n",
            "MLTSVM ->  0.3\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# print(\"------------------------------\")\n",
        "# print(\"\\t(Examples,Labels)\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",MLTSVM1_predictions.shape)\n",
        "# print(\"MLKNN  -> \",MLKNN1_predictions.shape)\n",
        "# print(\"BRKNNa -> \",BR1_predictions.shape)\n",
        "# import sklearn.metrics as m\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tHamming Loss\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tAccuracy\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "# print(\"\\tF1-measure\")\n",
        "# print(\"------------------------------\")\n",
        "# #f1=2*(p*r)/(p+r)\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcWI-UChJwd"
      },
      "source": [
        "# 02 Enron Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGr-CkgPhPwP",
        "outputId": "2dbe8d04-14dd-4069-f926-b8edf35cf9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(1702, 1001) (1702, 53)\n",
            "Coverted into Dataframe\n",
            "(1702, 1001) (1702, 53)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('enron', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x2=x.todense()\n",
        "y2=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x2=pd.DataFrame(x2)\n",
        "y2=pd.DataFrame(y2)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x2.shape,y2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5x0aoDoe2lr"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTHumYeCe2ls"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x2, y2, K=int((x2.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x2.columns):\n",
        "    if i not in selected_features:\n",
        "        x2 = x2.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pjB3qgce2ls",
        "outputId": "4c4a9b1a-b264-4761-b844-b22cdbbaa9ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1702, 568)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geaCWnlShd8V"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy72vS1uhdbF",
        "outputId": "aa75d568-623e-429d-c023-e6746f3e8200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1182, 568) (520, 568) (1182, 53) (520, 53)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x2 = s.csr_matrix(x2)\n",
        "y2 = s.csr_matrix(y2)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x2_train, y2_train, x2_test, y2_test = iterative_train_test_split(x2, y2, test_size = 0.3)\n",
        "print(x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UkG4qIhmA0"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQrV6hoHhnOl"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x2_train, y2_train)\n",
        "# predict\n",
        "MLTSVM2_predictions = classifier1.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4mQhAYhnu4"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9MCgnWXho55",
        "outputId": "b7ff1106-303a-4c5c-b1d1-3fa006968043"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=53 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for enron dataset it has 53 labels.\n",
        "classifier2 = MLkNN(k=53)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x2_train, y2_train)\n",
        "\n",
        "# predict\n",
        "MLKNN2_predictions = classifier2.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q77FQROhquS"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd-XcJd3hrtL"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=53)\n",
        "# train\n",
        "classifier3.fit(x2_train, y2_train)\n",
        "# predict\n",
        "BR2_predictions = classifier3.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s0jw9zchuXy"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRnvbkdhw6l"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "# hamming_loss_MLTSVM.append(round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "# hamming_loss_MLKNN.append(round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "# hamming_loss_BRKNNa.append(round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "\n",
        "# #Accuracy\n",
        "# accuracy_MLTSVM.append(round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "# accuracy_MLKNN.append(round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "# accuracy_BRKNNa.append(round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "# f1_measure_MLTSVM.append(round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_MLKNN.append(round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_BRKNNa.append(round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0inwYSohyl9",
        "outputId": "f7928fe3-d0d3-4a77-d5b5-054320ef4722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.43\n",
            "MLKNN ->  0.62\n",
            "BRKNNa ->  0.58\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.41\n",
            "MLTSVM ->  0.29\n",
            "MLTSVM ->  0.11\n"
          ]
        }
      ],
      "source": [
        "# print(\"------------------------------\")\n",
        "# print(\"\\t(Examples,Labels)\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",MLTSVM2_predictions.shape)\n",
        "# print(\"MLKNN  -> \",MLKNN2_predictions.shape)\n",
        "# print(\"BRKNNa -> \",BR2_predictions.shape)\n",
        "# import sklearn.metrics as m\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tHamming Loss\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tAccuracy\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tF1-measure\")\n",
        "# print(\"------------------------------\")\n",
        "# #f1=2*(p*r)/(p+r)\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2TXIFdh_nM"
      },
      "source": [
        "# 03 Scene Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMyBY_axh0sv",
        "outputId": "bc85eecc-5be7-478c-9b6d-e1e9d01e5ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scene:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(2407, 294) (2407, 6)\n",
            "Coverted into Dataframe\n",
            "(2407, 294) (2407, 6)\n"
          ]
        }
      ],
      "source": [
        "#from skmultilearn.dataset import load_dataset\n",
        "x3,y3, _, _ = load_dataset('scene', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x3.shape,y3.shape)\n",
        "#change to matrix\n",
        "x3=x3.todense()\n",
        "y3=y3.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x3=pd.DataFrame(x3)\n",
        "y3=pd.DataFrame(y3)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x3.shape,y3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnnbFucFe2l0"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSjFjr85e2l1"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x3, y3, K=int((x3.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x3.columns):\n",
        "    if i not in selected_features:\n",
        "        x3 = x3.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CWzZnmRe2l1",
        "outputId": "2ea428e4-7eec-494c-ad4b-4481a1e6e1e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2407, 164)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5196nOiRQy"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y164N9r1iUqs",
        "outputId": "c2c3bcea-1086-4b2a-b9db-4781aa19cc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1685, 164) (722, 164) (1685, 6) (722, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x3 = s.csr_matrix(x3)\n",
        "y3 = s.csr_matrix(y3)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x3_train, y3_train, x3_test, y3_test = iterative_train_test_split(x3, y3, test_size = 0.3)\n",
        "print(x3_train.shape, x3_test.shape, y3_train.shape, y3_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7i-TEOYibPk"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spSuhLrwiclk"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x3_train, y3_train)\n",
        "# predict\n",
        "MLTSVM3_predictions = classifier1.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDkyhEm-idLA"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEOsqkozieMm",
        "outputId": "f8508372-f866-458a-e1a1-453d30405702"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=6 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
          ]
        }
      ],
      "source": [
        "#from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for Scene dataset it has 6 labels.\n",
        "classifier2 = MLkNN(k=6)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x3_train, y3_train)\n",
        "\n",
        "# predict\n",
        "MLKNN3_predictions = classifier2.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soP4rbVxigYH"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8A69ylpiiIz"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=6)\n",
        "# train\n",
        "classifier3.fit(x3_train, y3_train)\n",
        "# predict\n",
        "BR3_predictions = classifier3.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8aWlmPiksm"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHQe8f4SinpS"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "# hamming_loss_MLTSVM.append(round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "# hamming_loss_MLKNN.append(round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "# hamming_loss_BRKNNa.append(round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "\n",
        "# #Accuracy\n",
        "# accuracy_MLTSVM.append(round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "# accuracy_MLKNN.append(round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "# accuracy_BRKNNa.append(round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y3_test, MLKNN3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y3_test, BR3_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "# f1_measure_MLTSVM.append(round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_MLKNN.append(round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_BRKNNa.append(round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAbuGy2aiqRN",
        "outputId": "723d2977-09ab-44e7-91b1-0e92500f57cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.18\n",
            "MLKNN ->  0.8\n",
            "BRKNNa ->  0.83\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.64\n",
            "BRKNNa ->  0.58\n"
          ]
        }
      ],
      "source": [
        "# print(\"------------------------------\")\n",
        "# print(\"\\t(Examples,Labels\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",MLTSVM3_predictions.shape)\n",
        "# print(\"MLKNN  -> \",MLKNN3_predictions.shape)\n",
        "# print(\"BRKNNa -> \",BR3_predictions.shape)\n",
        "# import sklearn.metrics as m\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tHamming Loss\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tAccuracy\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tF1-measure\")\n",
        "# print(\"------------------------------\")\n",
        "# #f1=2*(p*r)/(p+r)\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLKNN -> \",round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"BRKNNa -> \",round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDdYn841e2l-"
      },
      "source": [
        "# 04 Emotions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHWbljMHe2l-",
        "outputId": "c97cabf6-8f49-4847-eb24-63f3a06f3770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emotions:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(593, 72) (593, 6)\n",
            "Coverted into Dataframe\n",
            "(593, 72) (593, 6)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x4,y4, _, _ = load_dataset('emotions', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x4.shape,y4.shape)\n",
        "#change to matrix\n",
        "x4=x4.todense()\n",
        "y4=y4.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x4=pd.DataFrame(x4)\n",
        "y4=pd.DataFrame(y4)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x4.shape,y4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHNE-HKle2l_"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNoezCgZe2mA"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x4, y4, K=int((x4.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x4.columns):\n",
        "    if i not in selected_features:\n",
        "        x4 = x4.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "404IcsZ5e2mA",
        "outputId": "882c88de-8b9d-4e7f-c860-9dc3ea818dca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(593, 40)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjYYSO8jGMe"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqplGSrwjNaw",
        "outputId": "b3432efb-2369-4af5-e3a0-b08ac09ed983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(416, 40) (177, 40) (416, 6) (177, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x4 = s.csr_matrix(x4)\n",
        "y4 = s.csr_matrix(y4)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x4_train, y4_train, x4_test, y4_test = iterative_train_test_split(x4, y4, test_size = 0.3)\n",
        "print(x4_train.shape, x4_test.shape, y4_train.shape, y4_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-uX-BIqjSMZ"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XklOJNDOjTVt"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x4_train, y4_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgzlva3xjT5y"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7SIU5KbjUyx",
        "outputId": "d8a26a82-611d-4be9-9682-21f1a4785149"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=27 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x4_train, y4_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Yn9qcojXzz"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiUFTXdWjYxj"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x4_train, y4_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsQqXNfjbkI"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPZ71xjZjeBE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "# hamming_loss_MLTSVM.append(round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "# hamming_loss_MLKNN.append(round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "# hamming_loss_BRKNNa.append(round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "\n",
        "# #Accuracy\n",
        "# accuracy_MLTSVM.append(round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "# accuracy_MLKNN.append(round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "# accuracy_BRKNNa.append(round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y4_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y4_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "# f1_measure_MLTSVM.append(round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_MLKNN.append(round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_BRKNNa.append(round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ1wjsf7jgGo",
        "outputId": "ec2bdc3c-6f8b-4828-d1ac-2669135cf20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.32\n",
            "MLKNN ->  0.62\n",
            "MLKNNa ->  0.67\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.49\n",
            "BRKNNa ->  0.5\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# print(\"------------------------------\")\n",
        "# print(\"\\t(Examples,Labels\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "# print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "# print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "# import sklearn.metrics as m\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tHamming Loss\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tAccuracy\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "# print(\"\\tF1-measure\")\n",
        "# print(\"------------------------------\")\n",
        "# #f1=2*(p*r)/(p+r)\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLKNN -> \",round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"BRKNNa -> \",round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f_yd4hsisv3"
      },
      "source": [
        "# 05 Genbase Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irsKBHGqi5gK",
        "outputId": "6f273469-d301-4fff-be18-d301b0bd83dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "genbase:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(662, 1186) (662, 27)\n",
            "Coverted into Dataframe\n",
            "(662, 1186) (662, 27)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x5,y5, _, _ = load_dataset('genbase', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x5.shape,y5.shape)\n",
        "#change to matrix\n",
        "x5=x5.todense()\n",
        "y5=y5.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x5=pd.DataFrame(x5)\n",
        "y5=pd.DataFrame(y5)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x5.shape,y5.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48hjzoIOe2mK"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuwHt42je2mK",
        "outputId": "2d5c190f-be9e-433a-9913-ccb03f67d952"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [   1    2    3 ... 1183 1184 1185] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x5, y5, K=int((x5.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x5.columns):\n",
        "    if i not in selected_features:\n",
        "        x5 = x5.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYsyhmcme2mL",
        "outputId": "c30ee1c4-298e-4b28-b9bd-db5bffc5a802"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(662, 593)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE9io6O_e2mP"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3432efb-2369-4af5-e3a0-b08ac09ed983",
        "id": "lcXO3nVre2mQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(463, 593) (199, 593) (463, 27) (199, 27)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x5 = s.csr_matrix(x5)\n",
        "y5 = s.csr_matrix(y5)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x5_train, y5_train, x5_test, y5_test = iterative_train_test_split(x5, y5, test_size = 0.3)\n",
        "print(x5_train.shape, x5_test.shape, y5_train.shape, y5_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs1IfSR6e2mR"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyRYGLdie2mS"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x5_train, y5_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWDNwC51e2mS"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZh1SvI-e2mT",
        "outputId": "c8497a95-4a99-4b36-cd69-cc330b2e379c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=27 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x5_train, y5_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyMC7GO9e2mT"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iftrnt3He2mU"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x5_train, y5_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xCkD3VVe2mU"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXnpz_oMe2mV",
        "outputId": "14d21f42-6e99-49d5-a430-adca8894a39b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "# hamming_loss_MLTSVM.append(round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "# hamming_loss_MLKNN.append(round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "# hamming_loss_BRKNNa.append(round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "\n",
        "# #Accuracy\n",
        "# accuracy_MLTSVM.append(round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "# accuracy_MLKNN.append(round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "# accuracy_BRKNNa.append(round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y5_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y5_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "# f1_measure_MLTSVM.append(round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_MLKNN.append(round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "# f1_measure_BRKNNa.append(round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2bdc3c-6f8b-4828-d1ac-2669135cf20a",
        "id": "WBaMQJHBe2mV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.05\n",
            "MLKNN ->  0.0\n",
            "MLKNNa ->  0.0\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.0\n",
            "BRKNNa ->  0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Aashir\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# print(\"------------------------------\")\n",
        "# print(\"\\t(Examples,Labels\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "# print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "# print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "# import sklearn.metrics as m\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tHamming Loss\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tAccuracy\")\n",
        "# print(\"------------------------------\")\n",
        "# print(\"MLTSVM -> \",round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "# print(\"MLKNN  -> \",round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "# print(\"BRKNNa -> \",round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"------------------------------\")\n",
        "# print(\"\\tF1-measure\")\n",
        "# print(\"------------------------------\")\n",
        "# #f1=2*(p*r)/(p+r)\n",
        "# print(\"MLTSVM -> \",round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"MLKNN -> \",round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print(\"BRKNNa -> \",round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRgqpRadjiVz"
      },
      "source": [
        "# Results based on  EVALUATION MEASURES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bezV7sxyjsKJ"
      },
      "source": [
        "##Hamming Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXK9F7NXjrU5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dataset=['medical','enron','scene','gebase']\n",
        "hl=[]\n",
        "print(hamming_loss_MLKNN)\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,hamming_loss_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,hamming_loss_MLKNN, label='MLKNN',marker=\">\")\n",
        "ax.plot(dataset,hamming_loss_BRKNNa, label='BRKNNa',marker=\"*\")\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Hamming Loss')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-hamming loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTnz41Oxjv_P"
      },
      "source": [
        "##Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBO6ZTWvj0NS"
      },
      "outputs": [],
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,accuracy_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,accuracy_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,accuracy_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.savefig('chi-20-Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HCZyhktj1Dt"
      },
      "source": [
        "##Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bhk7Rtc1j4st"
      },
      "outputs": [],
      "source": [
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,precision_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,precision_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,precision_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro Precision')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-Precision')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBHu6gkj5nV"
      },
      "source": [
        "##Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tg4rjnKj6tB"
      },
      "outputs": [],
      "source": [
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,recall_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,recall_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,recall_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro Recall')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-Recall')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Dvi7SAj-iU"
      },
      "source": [
        "##F1 Measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfAzEw1kkAW-"
      },
      "outputs": [],
      "source": [
        "#F1 measure\n",
        "fig, ax=plt.subplots()\n",
        "ax.plot(dataset,f1_measure_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,f1_measure_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,f1_measure_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro F1 measure')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-f1 measure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILQqgkgtPktO"
      },
      "outputs": [],
      "source": [
        "#F1 measure\n",
        "fig, ax=plt.subplots()\n",
        "HL=[0.02, ]\n",
        "ax.plot(dataset,f1_measure_MLTSVM, label='MLTSVM',marker=\"H\")\n",
        "ax.plot(dataset,f1_measure_MLKNN, label='MLKNN',marker='>')\n",
        "ax.plot(dataset,f1_measure_BRKNNa, label='BRKNNa',marker='*')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Chi2 for 20% FS')\n",
        "ax.set_xlabel('Datasets')\n",
        "ax.set_ylabel('Micro F1 measure')\n",
        "plt.tight_layout()\n",
        "plt.savefig('chi-20-f1 measure')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}