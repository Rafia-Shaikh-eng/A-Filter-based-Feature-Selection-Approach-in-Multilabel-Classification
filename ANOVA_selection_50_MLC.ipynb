{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafia-Shaikh-eng/A-Filter-based-Feature-Selection-Approach-in-Multilabel-Classification/blob/main/ANOVA_selection_50_MLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdG1WwzQe26j"
      },
      "source": [
        "importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE70ALC9f3Ii"
      },
      "outputs": [],
      "source": [
        "# if the scikit-multilearn not installed run this cell\n",
        "!pip install scikit-multilearn\n",
        "# most of the datasets in Weka Arff format for this installed this library\n",
        "!pip install arff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEk8PbRke7t_"
      },
      "source": [
        "Created 03 arrays of each measuring metrics for 03 classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJucbp86f9vF"
      },
      "outputs": [],
      "source": [
        "#03 classifiers hamming loss list\n",
        "hamming_loss_MLTSVM=[]\n",
        "hamming_loss_MLKNN=[]\n",
        "hamming_loss_BRKNNa=[]\n",
        "#03 classifier accuracy list\n",
        "accuracy_MLTSVM=[]\n",
        "accuracy_MLKNN=[]\n",
        "accuracy_BRKNNa=[]\n",
        "#03 classifier precision list\n",
        "precision_MLTSVM=[]\n",
        "precision_MLKNN=[]\n",
        "precision_BRKNNa=[]\n",
        "#03 classifier recall list\n",
        "recall_MLTSVM=[]\n",
        "recall_MLKNN=[]\n",
        "recall_BRKNNa=[]\n",
        "#03 classifier f1 measure list\n",
        "f1_measure_MLTSVM=[]\n",
        "f1_measure_MLKNN=[]\n",
        "f1_measure_BRKNNa=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40EXuk8PgEWh"
      },
      "source": [
        "# 01 Medical Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QYSpg5gOSI",
        "outputId": "7c96dd69-4413-45ca-d2e5-110bb99eea32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(978, 1449) (978, 45)\n",
            "Coverted into Dataframe\n",
            "(978, 1449) (978, 45)\n"
          ]
        }
      ],
      "source": [
        "#Load Medical Dataset\n",
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('medical', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x1=x.todense()\n",
        "y1=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x1=pd.DataFrame(x1)\n",
        "y1=pd.DataFrame(y1)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x1.shape,y1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8-Z2QFVgBBq",
        "outputId": "bf407462-6fd3-4426-af4b-9f75ee603987"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(x1.shape[1]*0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVf2goSUgHDN"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiEIbif6gBBr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "def calculate_anova_score(X, Y):\n",
        "    anova_scores, _ = f_classif(X, Y)\n",
        "    return anova_scores\n",
        "\n",
        "def select_top_K_features(scores, K):\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    return sorted_indices[:K]\n",
        "\n",
        "def select_features(X, Y, K,p):\n",
        "    selected_features = set()\n",
        "    ANOVA = {}  # Create an empty dictionary\n",
        "\n",
        "    # Calculate ANOVA scores for each feature associated with each label\n",
        "    for label in Y.columns:\n",
        "        ANOVA[label] = calculate_anova_score(X, Y[label])\n",
        "\n",
        "    # Select top K features for each label\n",
        "    for label in ANOVA.keys():\n",
        "        topK = select_top_K_features(ANOVA[label], K)\n",
        "        ANOVA[label] = topK\n",
        "\n",
        "    # Count occurrences of selected features\n",
        "    feature_counts = {}\n",
        "    for label in ANOVA.keys():\n",
        "        for feature in ANOVA[label]:\n",
        "            if feature in feature_counts:\n",
        "                feature_counts[feature] += 1\n",
        "            else:\n",
        "                feature_counts[feature] = 1\n",
        "\n",
        "    # Select features based on the aggregated counts\n",
        "    for feature, count in feature_counts.items():\n",
        "        if count >= int(len((Y.columns))*p):  # Adjust this condition as needed\n",
        "            selected_features.add(feature)\n",
        "\n",
        "    return selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3saEOeGFYP1u"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x1, y1, K=int((x1.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x1.columns):\n",
        "    if i not in selected_features:\n",
        "        x1 = x1.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Ir4x3cgBBt",
        "outputId": "73a1636e-40b2-450e-fa91-f51a5e30f548"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(978, 726)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYNehoigr6n"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U8kN0z8gizm",
        "outputId": "ea6db50f-71d5-41ed-c48e-9b88aee62a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(685, 726) (293, 726) (685, 45) (293, 45)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x1 = s.csr_matrix(x1)\n",
        "y1 = s.csr_matrix(y1)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x1_train, y1_train, x1_test, y1_test = iterative_train_test_split(x1, y1, test_size = 0.3)\n",
        "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCLP9vog4NE"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNkimd9guHp"
      },
      "outputs": [],
      "source": [
        "#MLTSVM\n",
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(max_iteration=1000,c_k=2**-6)\n",
        "# train\n",
        "classifier1.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLTSVM1_predictions = classifier1.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YUC40jeg6Ca"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCT3Jbj1g7L2"
      },
      "outputs": [],
      "source": [
        "#MLKNN\n",
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for medical dataset it has 45 labels.\n",
        "classifier2 = MLkNN(k=45)\n",
        "# train\n",
        "classifier2.fit(x1_train, y1_train)\n",
        "# self.knn_ = NearestNeighbors(n_neighbors=self.k).fit(X)\n",
        "# predict\n",
        "MLKNN1_predictions = classifier2.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1w6zZiEg7nQ"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_tHDGxjg8nK"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=45)\n",
        "# train\n",
        "classifier3.fit(x1_train, y1_train)\n",
        "# predict\n",
        "BR1_predictions = classifier3.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqkcSY2whDb9"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf4blT91Yb-I"
      },
      "source": [
        "# Kindly do not comment any of the measuring metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swSBdm1RYb6x"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6FQQ9MxhFX-"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ynx5rIJIhHai",
        "outputId": "5564b632-3eae-494b-eab1-d9a16c740a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (293, 45)\n",
            "MLKNN  ->  (293, 45)\n",
            "BRKNNa ->  (293, 45)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.02\n",
            "BRKNNa ->  0.02\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.49\n",
            "MLKNN  ->  0.39\n",
            "BRKNNa ->  0.26\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.76\n",
            "MLKNN ->  0.83\n",
            "BRKNNa ->  0.85\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.65\n",
            "MLTSVM ->  0.46\n",
            "MLTSVM ->  0.31\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.7\n",
            "MLTSVM ->  0.59\n",
            "MLTSVM ->  0.45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM1_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN1_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR1_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcWI-UChJwd"
      },
      "source": [
        "# 02 Enron Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGr-CkgPhPwP",
        "outputId": "0c5f99c8-18ea-4092-f507-faa8fc9e928d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(1702, 1001) (1702, 53)\n",
            "Coverted into Dataframe\n",
            "(1702, 1001) (1702, 53)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('enron', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x2=x.todense()\n",
        "y2=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x2=pd.DataFrame(x2)\n",
        "y2=pd.DataFrame(y2)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x2.shape,y2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nr7n_YFgBBx"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAoPvJxKgBBy"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x2, y2, K=int((x2.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x2.columns):\n",
        "    if i not in selected_features:\n",
        "        x2 = x2.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Hd_oQtgBBy",
        "outputId": "3edf44c7-aac5-4735-b13f-410eac28078f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1702, 568)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geaCWnlShd8V"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy72vS1uhdbF",
        "outputId": "083be192-3de9-4bef-c111-04ffc02fcc37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1187, 568) (515, 568) (1187, 53) (515, 53)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x2 = s.csr_matrix(x2)\n",
        "y2 = s.csr_matrix(y2)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x2_train, y2_train, x2_test, y2_test = iterative_train_test_split(x2, y2, test_size = 0.3)\n",
        "print(x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UkG4qIhmA0"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQrV6hoHhnOl"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x2_train, y2_train)\n",
        "# predict\n",
        "MLTSVM2_predictions = classifier1.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4mQhAYhnu4"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9MCgnWXho55"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for enron dataset it has 53 labels.\n",
        "classifier2 = MLkNN(k=53)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x2_train, y2_train)\n",
        "\n",
        "# predict\n",
        "MLKNN2_predictions = classifier2.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q77FQROhquS"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd-XcJd3hrtL"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=53)\n",
        "# train\n",
        "classifier3.fit(x2_train, y2_train)\n",
        "# predict\n",
        "BR2_predictions = classifier3.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s0jw9zchuXy"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRnvbkdhw6l"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0inwYSohyl9",
        "outputId": "3be8f0b3-28a5-46bf-c365-2cfb075f951f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (515, 53)\n",
            "MLKNN  ->  (515, 53)\n",
            "BRKNNa ->  (515, 53)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.07\n",
            "MLKNN  ->  0.06\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.06\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.43\n",
            "MLKNN ->  0.62\n",
            "BRKNNa ->  0.59\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.4\n",
            "MLTSVM ->  0.28\n",
            "MLTSVM ->  0.11\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.41\n",
            "MLTSVM ->  0.38\n",
            "MLTSVM ->  0.18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM2_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN2_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR2_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2TXIFdh_nM"
      },
      "source": [
        "# 03 Scene Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMyBY_axh0sv",
        "outputId": "aa4b9c3c-3f2b-4017-fe2e-c683d1675933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scene:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(2407, 294) (2407, 6)\n",
            "Coverted into Dataframe\n",
            "(2407, 294) (2407, 6)\n"
          ]
        }
      ],
      "source": [
        "#from skmultilearn.dataset import load_dataset\n",
        "x3,y3, _, _ = load_dataset('scene', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x3.shape,y3.shape)\n",
        "#change to matrix\n",
        "x3=x3.todense()\n",
        "y3=y3.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x3=pd.DataFrame(x3)\n",
        "y3=pd.DataFrame(y3)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x3.shape,y3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DixxE-KLgBB3"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76eM05XKgBB3"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x3, y3, K=int((x3.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x3.columns):\n",
        "    if i not in selected_features:\n",
        "        x3 = x3.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sECH7a9cgBB3",
        "outputId": "13b1ad23-b516-4a6e-ff99-2cbf435f976c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2407, 164)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5196nOiRQy"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y164N9r1iUqs",
        "outputId": "818f6ae5-6234-461f-adec-b0b39466644b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1685, 164) (722, 164) (1685, 6) (722, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x3 = s.csr_matrix(x3)\n",
        "y3 = s.csr_matrix(y3)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x3_train, y3_train, x3_test, y3_test = iterative_train_test_split(x3, y3, test_size = 0.3)\n",
        "print(x3_train.shape, x3_test.shape, y3_train.shape, y3_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7i-TEOYibPk"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spSuhLrwiclk"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x3_train, y3_train)\n",
        "# predict\n",
        "MLTSVM3_predictions = classifier1.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDkyhEm-idLA"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEOsqkozieMm"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for Scene dataset it has 6 labels.\n",
        "classifier2 = MLkNN(k=6)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x3_train, y3_train)\n",
        "\n",
        "# predict\n",
        "MLKNN3_predictions = classifier2.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soP4rbVxigYH"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8A69ylpiiIz"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=6)\n",
        "# train\n",
        "classifier3.fit(x3_train, y3_train)\n",
        "# predict\n",
        "BR3_predictions = classifier3.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8aWlmPiksm"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHQe8f4SinpS"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y3_test, MLKNN3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y3_test, BR3_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAbuGy2aiqRN",
        "outputId": "b041c0ec-7fa2-48c3-effa-bb798297b5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (722, 6)\n",
            "MLKNN  ->  (722, 6)\n",
            "BRKNNa ->  (722, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.79\n",
            "MLKNN  ->  0.09\n",
            "BRKNNa ->  0.1\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.61\n",
            "BRKNNa ->  0.57\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.18\n",
            "MLKNN ->  0.8\n",
            "BRKNNa ->  0.83\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.64\n",
            "BRKNNa ->  0.58\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.31\n",
            "MLKNN ->  0.71\n",
            "BRKNNa ->  0.68\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM3_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN3_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR3_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFQFC02CgBB6"
      },
      "source": [
        "# 04 Emotions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y62mkwdgBB6",
        "outputId": "b22777d5-8e5e-499b-a644-eae8f534dfdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emotions:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(593, 72) (593, 6)\n",
            "Coverted into Dataframe\n",
            "(593, 72) (593, 6)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x4,y4, _, _ = load_dataset('emotions', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x4.shape,y4.shape)\n",
        "#change to matrix\n",
        "x4=x4.todense()\n",
        "y4=y4.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x4=pd.DataFrame(x4)\n",
        "y4=pd.DataFrame(y4)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x4.shape,y4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXvJdhrPgBB7"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjyWhnslgBB7"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x4, y4, K=int((x4.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x4.columns):\n",
        "    if i not in selected_features:\n",
        "        x4 = x4.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AOgovc2gBB7",
        "outputId": "0079ebe4-ebd2-415d-d67a-a056511fad54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(593, 40)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjYYSO8jGMe"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqplGSrwjNaw",
        "outputId": "ccab3f4c-a982-4c71-bc9f-ee8c2469a329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(416, 40) (177, 40) (416, 6) (177, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x4 = s.csr_matrix(x4)\n",
        "y4 = s.csr_matrix(y4)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x4_train, y4_train, x4_test, y4_test = iterative_train_test_split(x4, y4, test_size = 0.3)\n",
        "print(x4_train.shape, x4_test.shape, y4_train.shape, y4_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-uX-BIqjSMZ"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XklOJNDOjTVt"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x4_train, y4_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgzlva3xjT5y"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7SIU5KbjUyx"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x4_train, y4_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Yn9qcojXzz"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiUFTXdWjYxj"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x4_train, y4_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsQqXNfjbkI"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPZ71xjZjeBE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y4_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y4_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ1wjsf7jgGo",
        "outputId": "f3353318-d346-4655-93eb-78c54d4e7a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (177, 6)\n",
            "MLKNN  ->  (177, 6)\n",
            "BRKNNa ->  (177, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.68\n",
            "MLKNN  ->  0.24\n",
            "BRKNNa ->  0.25\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.2\n",
            "BRKNNa ->  0.19\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.32\n",
            "MLKNN ->  0.65\n",
            "MLKNNa ->  0.66\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.49\n",
            "BRKNNa ->  0.48\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.48\n",
            "MLKNN ->  0.56\n",
            "BRKNNa ->  0.55\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f_yd4hsisv3"
      },
      "source": [
        "# 05 Genbase Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irsKBHGqi5gK",
        "outputId": "eaa3fbed-3154-4c7e-b633-0b95fab38357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "genbase:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(662, 1186) (662, 27)\n",
            "Coverted into Dataframe\n",
            "(662, 1186) (662, 27)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x5,y5, _, _ = load_dataset('genbase', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x5.shape,y5.shape)\n",
        "#change to matrix\n",
        "x5=x5.todense()\n",
        "y5=y5.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x5=pd.DataFrame(x5)\n",
        "y5=pd.DataFrame(y5)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x5.shape,y5.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MsEvCGPgBCA"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhyxvbEdgBCA"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x5, y5, K=int((x5.shape[1])*0.5),p=0.5)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x5.columns):\n",
        "    if i not in selected_features:\n",
        "        x5 = x5.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtH6wKl2gBCA",
        "outputId": "9b0ebfaf-57ae-46ec-8f6a-f672f9fcd48f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(662, 593)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix8Zu0eDgBCB"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK_kWxhfgBCB",
        "outputId": "20b7009d-0120-44ec-b9c5-839cb2a0c3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(463, 593) (199, 593) (463, 27) (199, 27)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x5 = s.csr_matrix(x5)\n",
        "y5 = s.csr_matrix(y5)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x5_train, y5_train, x5_test, y5_test = iterative_train_test_split(x5, y5, test_size = 0.3)\n",
        "print(x5_train.shape, x5_test.shape, y5_train.shape, y5_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmCAVEMgBCB"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo4ILCWegBCC"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x5_train, y5_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMS2rOC4gBCC"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLsvZV3_gBCC"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x5_train, y5_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C0Bo086gBCD"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYZO36HOgBCD"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x5_train, y5_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXqzws2ogBCD"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUeOKiZ9gBCE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y5_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y5_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlZfJajvgBCE"
      },
      "outputs": [],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}