{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafia-Shaikh-eng/A-Filter-based-Feature-Selection-Approach-in-Multilabel-Classification/blob/main/ANOVA_selection_80_MLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdG1WwzQe26j"
      },
      "source": [
        "importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE70ALC9f3Ii"
      },
      "outputs": [],
      "source": [
        "# if the scikit-multilearn not installed run this cell\n",
        "!pip install scikit-multilearn\n",
        "# most of the datasets in Weka Arff format for this installed this library\n",
        "!pip install arff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEk8PbRke7t_"
      },
      "source": [
        "Created 03 arrays of each measuring metrics for 03 classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJucbp86f9vF"
      },
      "outputs": [],
      "source": [
        "#03 classifiers hamming loss list\n",
        "hamming_loss_MLTSVM=[]\n",
        "hamming_loss_MLKNN=[]\n",
        "hamming_loss_BRKNNa=[]\n",
        "#03 classifier accuracy list\n",
        "accuracy_MLTSVM=[]\n",
        "accuracy_MLKNN=[]\n",
        "accuracy_BRKNNa=[]\n",
        "#03 classifier precision list\n",
        "precision_MLTSVM=[]\n",
        "precision_MLKNN=[]\n",
        "precision_BRKNNa=[]\n",
        "#03 classifier recall list\n",
        "recall_MLTSVM=[]\n",
        "recall_MLKNN=[]\n",
        "recall_BRKNNa=[]\n",
        "#03 classifier f1 measure list\n",
        "f1_measure_MLTSVM=[]\n",
        "f1_measure_MLKNN=[]\n",
        "f1_measure_BRKNNa=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40EXuk8PgEWh"
      },
      "source": [
        "# 01 Medical Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QYSpg5gOSI",
        "outputId": "7c96dd69-4413-45ca-d2e5-110bb99eea32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(978, 1449) (978, 45)\n",
            "Coverted into Dataframe\n",
            "(978, 1449) (978, 45)\n"
          ]
        }
      ],
      "source": [
        "#Load Medical Dataset\n",
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('medical', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x1=x.todense()\n",
        "y1=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x1=pd.DataFrame(x1)\n",
        "y1=pd.DataFrame(y1)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x1.shape,y1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8-Z2QFVgBBq"
      },
      "outputs": [],
      "source": [
        "# int(x1.shape[1]*0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVf2goSUgHDN"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiEIbif6gBBr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "def calculate_anova_score(X, Y):\n",
        "    anova_scores, _ = f_classif(X, Y)\n",
        "    return anova_scores\n",
        "\n",
        "def select_top_K_features(scores, K):\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    return sorted_indices[:K]\n",
        "\n",
        "def select_features(X, Y, K,p):\n",
        "    selected_features = set()\n",
        "    ANOVA = {}  # Create an empty dictionary\n",
        "\n",
        "    # Calculate ANOVA scores for each feature associated with each label\n",
        "    for label in Y.columns:\n",
        "        ANOVA[label] = calculate_anova_score(X, Y[label])\n",
        "\n",
        "    # Select top K features for each label\n",
        "    for label in ANOVA.keys():\n",
        "        topK = select_top_K_features(ANOVA[label], K)\n",
        "        ANOVA[label] = topK\n",
        "\n",
        "    # Count occurrences of selected features\n",
        "    feature_counts = {}\n",
        "    for label in ANOVA.keys():\n",
        "        for feature in ANOVA[label]:\n",
        "            if feature in feature_counts:\n",
        "                feature_counts[feature] += 1\n",
        "            else:\n",
        "                feature_counts[feature] = 1\n",
        "\n",
        "    # Select features based on the aggregated counts\n",
        "    for feature, count in feature_counts.items():\n",
        "        if count >= int(len((Y.columns))*p):  # Adjust this condition as needed\n",
        "            selected_features.add(feature)\n",
        "\n",
        "    return selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3saEOeGFYP1u"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x1, y1, K=int((x1.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x1.columns):\n",
        "    if i not in selected_features:\n",
        "        x1 = x1.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Ir4x3cgBBt",
        "outputId": "73a1636e-40b2-450e-fa91-f51a5e30f548"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(978, 1114)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYNehoigr6n"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U8kN0z8gizm",
        "outputId": "ea6db50f-71d5-41ed-c48e-9b88aee62a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(687, 1114) (291, 1114) (687, 45) (291, 45)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x1 = s.csr_matrix(x1)\n",
        "y1 = s.csr_matrix(y1)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x1_train, y1_train, x1_test, y1_test = iterative_train_test_split(x1, y1, test_size = 0.3)\n",
        "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCLP9vog4NE"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNkimd9guHp"
      },
      "outputs": [],
      "source": [
        "#MLTSVM\n",
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(max_iteration=1000,c_k=2**-6)\n",
        "# train\n",
        "classifier1.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLTSVM1_predictions = classifier1.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YUC40jeg6Ca"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCT3Jbj1g7L2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#MLKNN\n",
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for medical dataset it has 45 labels.\n",
        "classifier2 = MLkNN(k=45)\n",
        "# train\n",
        "classifier2.fit(x1_train, y1_train)\n",
        "# self.knn_ = NearestNeighbors(n_neighbors=self.k).fit(X)\n",
        "# predict\n",
        "MLKNN1_predictions = classifier2.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1w6zZiEg7nQ"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_tHDGxjg8nK"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=45)\n",
        "# train\n",
        "classifier3.fit(x1_train, y1_train)\n",
        "# predict\n",
        "BR1_predictions = classifier3.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqkcSY2whDb9"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf4blT91Yb-I"
      },
      "source": [
        "# Kindly do not comment any of the measuring metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swSBdm1RYb6x"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6FQQ9MxhFX-"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ynx5rIJIhHai",
        "outputId": "16ab9e92-7f70-4efb-b725-710f623ed174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (291, 45)\n",
            "MLKNN  ->  (291, 45)\n",
            "BRKNNa ->  (291, 45)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.02\n",
            "BRKNNa ->  0.02\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.47\n",
            "MLKNN  ->  0.44\n",
            "BRKNNa ->  0.26\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.75\n",
            "MLKNN ->  0.88\n",
            "BRKNNa ->  0.84\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.65\n",
            "MLTSVM ->  0.5\n",
            "MLTSVM ->  0.31\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.7\n",
            "MLTSVM ->  0.64\n",
            "MLTSVM ->  0.45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM1_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN1_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR1_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcWI-UChJwd"
      },
      "source": [
        "# 02 Enron Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGr-CkgPhPwP",
        "outputId": "25140c87-ab16-4182-f18d-aeda0d35dc20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(1702, 1001) (1702, 53)\n",
            "Coverted into Dataframe\n",
            "(1702, 1001) (1702, 53)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('enron', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x2=x.todense()\n",
        "y2=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x2=pd.DataFrame(x2)\n",
        "y2=pd.DataFrame(y2)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x2.shape,y2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nr7n_YFgBBx"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAoPvJxKgBBy"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x2, y2, K=int((x2.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x2.columns):\n",
        "    if i not in selected_features:\n",
        "        x2 = x2.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Hd_oQtgBBy",
        "outputId": "73c3fbe1-e8af-4dc8-f176-2323cba6ddfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1702, 618)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geaCWnlShd8V"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy72vS1uhdbF",
        "outputId": "bf13a81a-152d-41f5-9053-68079ba5a852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1182, 618) (520, 618) (1182, 53) (520, 53)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x2 = s.csr_matrix(x2)\n",
        "y2 = s.csr_matrix(y2)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x2_train, y2_train, x2_test, y2_test = iterative_train_test_split(x2, y2, test_size = 0.3)\n",
        "print(x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UkG4qIhmA0"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQrV6hoHhnOl"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x2_train, y2_train)\n",
        "# predict\n",
        "MLTSVM2_predictions = classifier1.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4mQhAYhnu4"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9MCgnWXho55"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for enron dataset it has 53 labels.\n",
        "classifier2 = MLkNN(k=53)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x2_train, y2_train)\n",
        "\n",
        "# predict\n",
        "MLKNN2_predictions = classifier2.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q77FQROhquS"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd-XcJd3hrtL"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=53)\n",
        "# train\n",
        "classifier3.fit(x2_train, y2_train)\n",
        "# predict\n",
        "BR2_predictions = classifier3.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s0jw9zchuXy"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRnvbkdhw6l"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0inwYSohyl9",
        "outputId": "9a0ca38a-3ce4-47f4-a04d-af9fe31ecbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (520, 53)\n",
            "MLKNN  ->  (520, 53)\n",
            "BRKNNa ->  (520, 53)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.08\n",
            "MLKNN  ->  0.06\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.04\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.39\n",
            "MLKNN ->  0.61\n",
            "BRKNNa ->  0.5\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.46\n",
            "MLTSVM ->  0.28\n",
            "MLTSVM ->  0.11\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.42\n",
            "MLTSVM ->  0.39\n",
            "MLTSVM ->  0.18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM2_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN2_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR2_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2TXIFdh_nM"
      },
      "source": [
        "# 03 Scene Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMyBY_axh0sv",
        "outputId": "c638a747-abd4-44dd-a4b2-3f31d3ec80ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scene:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(2407, 294) (2407, 6)\n",
            "Coverted into Dataframe\n",
            "(2407, 294) (2407, 6)\n"
          ]
        }
      ],
      "source": [
        "#from skmultilearn.dataset import load_dataset\n",
        "x3,y3, _, _ = load_dataset('scene', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x3.shape,y3.shape)\n",
        "#change to matrix\n",
        "x3=x3.todense()\n",
        "y3=y3.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x3=pd.DataFrame(x3)\n",
        "y3=pd.DataFrame(y3)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x3.shape,y3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DixxE-KLgBB3"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76eM05XKgBB3"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x3, y3, K=int((x3.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x3.columns):\n",
        "    if i not in selected_features:\n",
        "        x3 = x3.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sECH7a9cgBB3",
        "outputId": "7fab01f3-5ee2-43ae-f4f2-a18b2fbe34ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2407, 247)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5196nOiRQy"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y164N9r1iUqs",
        "outputId": "c96ec9a3-6253-43b2-ea0f-d1cfbb1e6e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1685, 247) (722, 247) (1685, 6) (722, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x3 = s.csr_matrix(x3)\n",
        "y3 = s.csr_matrix(y3)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x3_train, y3_train, x3_test, y3_test = iterative_train_test_split(x3, y3, test_size = 0.3)\n",
        "print(x3_train.shape, x3_test.shape, y3_train.shape, y3_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7i-TEOYibPk"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spSuhLrwiclk"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x3_train, y3_train)\n",
        "# predict\n",
        "MLTSVM3_predictions = classifier1.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDkyhEm-idLA"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEOsqkozieMm"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for Scene dataset it has 6 labels.\n",
        "classifier2 = MLkNN(k=6)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x3_train, y3_train)\n",
        "\n",
        "# predict\n",
        "MLKNN3_predictions = classifier2.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soP4rbVxigYH"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8A69ylpiiIz"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=6)\n",
        "# train\n",
        "classifier3.fit(x3_train, y3_train)\n",
        "# predict\n",
        "BR3_predictions = classifier3.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8aWlmPiksm"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHQe8f4SinpS"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "# #Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y3_test, MLKNN3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y3_test, BR3_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "# #Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAbuGy2aiqRN",
        "outputId": "9cdb5032-5f64-4762-b5c1-84d6b2b78643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (722, 6)\n",
            "MLKNN  ->  (722, 6)\n",
            "BRKNNa ->  (722, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.7\n",
            "MLKNN  ->  0.09\n",
            "BRKNNa ->  0.1\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.64\n",
            "BRKNNa ->  0.58\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.2\n",
            "MLKNN ->  0.77\n",
            "BRKNNa ->  0.83\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.7\n",
            "BRKNNa ->  0.58\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.34\n",
            "MLKNN ->  0.73\n",
            "BRKNNa ->  0.69\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM3_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN3_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR3_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "# print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFQFC02CgBB6"
      },
      "source": [
        "# 04 Emotions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y62mkwdgBB6",
        "outputId": "fb0594e0-08fe-45e9-dda8-c260ac1c6c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emotions:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(593, 72) (593, 6)\n",
            "Coverted into Dataframe\n",
            "(593, 72) (593, 6)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x4,y4, _, _ = load_dataset('emotions', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x4.shape,y4.shape)\n",
        "#change to matrix\n",
        "x4=x4.todense()\n",
        "y4=y4.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x4=pd.DataFrame(x4)\n",
        "y4=pd.DataFrame(y4)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x4.shape,y4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXvJdhrPgBB7"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjyWhnslgBB7"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x4, y4, K=int((x4.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x4.columns):\n",
        "    if i not in selected_features:\n",
        "        x4 = x4.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AOgovc2gBB7",
        "outputId": "75d09fff-ddae-4c54-e0c8-2541ebdb5192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(593, 59)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjYYSO8jGMe"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqplGSrwjNaw",
        "outputId": "d5f9f6b5-e6c7-41e7-a53d-4c8ba964ccff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(417, 59) (176, 59) (417, 6) (176, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x4 = s.csr_matrix(x4)\n",
        "y4 = s.csr_matrix(y4)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x4_train, y4_train, x4_test, y4_test = iterative_train_test_split(x4, y4, test_size = 0.3)\n",
        "print(x4_train.shape, x4_test.shape, y4_train.shape, y4_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-uX-BIqjSMZ"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XklOJNDOjTVt"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x4_train, y4_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgzlva3xjT5y"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7SIU5KbjUyx"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x4_train, y4_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Yn9qcojXzz"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiUFTXdWjYxj"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x4_train, y4_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsQqXNfjbkI"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPZ71xjZjeBE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y4_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y4_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ1wjsf7jgGo",
        "outputId": "7a96ecb8-9c3e-4a66-90c7-94a8da083012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (176, 6)\n",
            "MLKNN  ->  (176, 6)\n",
            "BRKNNa ->  (176, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.68\n",
            "MLKNN  ->  0.28\n",
            "BRKNNa ->  0.25\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.08\n",
            "BRKNNa ->  0.12\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.32\n",
            "MLKNN ->  0.61\n",
            "MLKNNa ->  0.71\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.31\n",
            "BRKNNa ->  0.33\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.48\n",
            "MLKNN ->  0.41\n",
            "BRKNNa ->  0.45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f_yd4hsisv3"
      },
      "source": [
        "# 05 Genbase Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irsKBHGqi5gK",
        "outputId": "3a2f77a4-2b9f-463d-9718-b99a116b1f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "genbase:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(662, 1186) (662, 27)\n",
            "Coverted into Dataframe\n",
            "(662, 1186) (662, 27)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x5,y5, _, _ = load_dataset('genbase', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x5.shape,y5.shape)\n",
        "#change to matrix\n",
        "x5=x5.todense()\n",
        "y5=y5.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x5=pd.DataFrame(x5)\n",
        "y5=pd.DataFrame(y5)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x5.shape,y5.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MsEvCGPgBCA"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhyxvbEdgBCA"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x5, y5, K=int((x5.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x5.columns):\n",
        "    if i not in selected_features:\n",
        "        x5 = x5.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtH6wKl2gBCA",
        "outputId": "ec599361-3ace-4c2a-9e8e-b588beeb3310"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(662, 948)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix8Zu0eDgBCB"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK_kWxhfgBCB",
        "outputId": "6bc6531c-d1c5-454e-f21b-3e5b97ce99b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(463, 948) (199, 948) (463, 27) (199, 27)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x5 = s.csr_matrix(x5)\n",
        "y5 = s.csr_matrix(y5)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x5_train, y5_train, x5_test, y5_test = iterative_train_test_split(x5, y5, test_size = 0.3)\n",
        "print(x5_train.shape, x5_test.shape, y5_train.shape, y5_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmCAVEMgBCB"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo4ILCWegBCC"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x5_train, y5_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMS2rOC4gBCC"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLsvZV3_gBCC"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x5_train, y5_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C0Bo086gBCD"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYZO36HOgBCD"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x5_train, y5_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXqzws2ogBCD"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUeOKiZ9gBCE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y5_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y5_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlZfJajvgBCE"
      },
      "outputs": [],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}