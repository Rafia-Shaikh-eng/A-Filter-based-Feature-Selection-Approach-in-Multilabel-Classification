{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafia-Shaikh-eng/A-Filter-based-Feature-Selection-Approach-in-Multilabel-Classification/blob/main/Fisher_Score_Feature_selection_80_MLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdG1WwzQe26j"
      },
      "source": [
        "importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE70ALC9f3Ii"
      },
      "outputs": [],
      "source": [
        "# if the scikit-multilearn not installed run this cell\n",
        "!pip install scikit-multilearn\n",
        "# most of the datasets in Weka Arff format for this installed this library\n",
        "!pip install arff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEk8PbRke7t_"
      },
      "source": [
        "Created 03 arrays of each measuring metrics for 03 classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJucbp86f9vF"
      },
      "outputs": [],
      "source": [
        "#03 classifiers hamming loss list\n",
        "hamming_loss_MLTSVM=[]\n",
        "hamming_loss_MLKNN=[]\n",
        "hamming_loss_BRKNNa=[]\n",
        "#03 classifier accuracy list\n",
        "accuracy_MLTSVM=[]\n",
        "accuracy_MLKNN=[]\n",
        "accuracy_BRKNNa=[]\n",
        "#03 classifier precision list\n",
        "precision_MLTSVM=[]\n",
        "precision_MLKNN=[]\n",
        "precision_BRKNNa=[]\n",
        "#03 classifier recall list\n",
        "recall_MLTSVM=[]\n",
        "recall_MLKNN=[]\n",
        "recall_BRKNNa=[]\n",
        "#03 classifier f1 measure list\n",
        "f1_measure_MLTSVM=[]\n",
        "f1_measure_MLKNN=[]\n",
        "f1_measure_BRKNNa=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40EXuk8PgEWh"
      },
      "source": [
        "# 01 Medical Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QYSpg5gOSI",
        "outputId": "18c2d6f0-7e6c-4ae5-8277-325348da93a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(978, 1449) (978, 45)\n",
            "Coverted into Dataframe\n",
            "(978, 1449) (978, 45)\n"
          ]
        }
      ],
      "source": [
        "#Load Medical Dataset\n",
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('medical', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x1=x.todense()\n",
        "y1=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x1=pd.DataFrame(x1)\n",
        "y1=pd.DataFrame(y1)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x1.shape,y1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_IcZ0T9-x1p",
        "outputId": "2f9c126c-b71c-4ca9-adad-1a522f6dc774"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1159"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(x1.shape[1]*0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVf2goSUgHDN"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAeuPBI0-x1p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "def calculate_fisher_score(X, Y):\n",
        "    fisher_scores, _ = f_classif(X, Y)\n",
        "    return fisher_scores\n",
        "\n",
        "def select_top_K_features(scores, K):\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    return sorted_indices[:K]\n",
        "\n",
        "def select_features(X, Y, K,p):\n",
        "    selected_features = set()\n",
        "    MI = {}  # Create an empty dictionary\n",
        "\n",
        "    # Calculate Fisher's scores for each feature associated with each label\n",
        "    for label in Y.columns:\n",
        "        MI[label] = calculate_fisher_score(X, Y[label])\n",
        "    # Select top K features for each label\n",
        "    for label in MI.keys():\n",
        "        topK = select_top_K_features(MI[label], K)\n",
        "        MI[label] = topK\n",
        "    # Count occurrences of selected features\n",
        "    feature_counts = {}\n",
        "    for label in MI.keys():\n",
        "        for feature in MI[label]:\n",
        "            if feature in feature_counts:\n",
        "                feature_counts[feature] += 1\n",
        "            else:\n",
        "                feature_counts[feature] = 1\n",
        "\n",
        "    # Select features based on the aggregated counts\n",
        "    for feature, count in feature_counts.items():\n",
        "        if count >= int(len((Y.columns))*p):  # Adjust this condition as needed\n",
        "            selected_features.add(feature)\n",
        "\n",
        "    return selected_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpLSnkRd-x1q"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x1, y1, K=int((x1.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x1.columns):\n",
        "    if i not in selected_features:\n",
        "        x1 = x1.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyZSU6Ec-x1r",
        "outputId": "0ab5370a-cc5d-4194-ce2b-c08e0cb47f4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(978, 1114)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYNehoigr6n"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U8kN0z8gizm",
        "outputId": "646c126a-0fd1-4dff-85a2-3d12e23c8d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(685, 1114) (293, 1114) (685, 45) (293, 45)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x1 = s.csr_matrix(x1)\n",
        "y1 = s.csr_matrix(y1)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x1_train, y1_train, x1_test, y1_test = iterative_train_test_split(x1, y1, test_size = 0.3)\n",
        "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCLP9vog4NE"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNkimd9guHp"
      },
      "outputs": [],
      "source": [
        "#MLTSVM\n",
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(max_iteration=1000,c_k=2**-6)\n",
        "# train\n",
        "classifier1.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLTSVM1_predictions = classifier1.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YUC40jeg6Ca"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCT3Jbj1g7L2"
      },
      "outputs": [],
      "source": [
        "#MLKNN\n",
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for medical dataset it has 45 labels.\n",
        "classifier2 = MLkNN(k=45)\n",
        "# train\n",
        "classifier2.fit(x1_train, y1_train)\n",
        "# predict\n",
        "MLKNN1_predictions = classifier2.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1w6zZiEg7nQ"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_tHDGxjg8nK"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=45)\n",
        "# train\n",
        "classifier3.fit(x1_train, y1_train)\n",
        "# predict\n",
        "BR1_predictions = classifier3.predict(x1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqkcSY2whDb9"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6FQQ9MxhFX-"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynx5rIJIhHai",
        "outputId": "1905c0e9-ee46-45f5-a4f9-816457ab83e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (293, 45)\n",
            "MLKNN  ->  (293, 45)\n",
            "BRKNNa ->  (293, 45)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.02\n",
            "BRKNNa ->  0.02\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.49\n",
            "MLKNN  ->  0.43\n",
            "BRKNNa ->  0.25\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.76\n",
            "MLKNN ->  0.86\n",
            "BRKNNa ->  0.83\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.66\n",
            "MLTSVM ->  0.51\n",
            "MLTSVM ->  0.3\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.71\n",
            "MLTSVM ->  0.64\n",
            "MLTSVM ->  0.44\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM1_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN1_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR1_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y1_test, BR1_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y1_test, MLTSVM1_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y1_test, MLKNN1_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y1_test, BR1_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y1_test, MLTSVM1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y1_test, MLKNN1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y1_test, BR1_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLTSVM1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, MLKNN1_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y1_test, BR1_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcWI-UChJwd"
      },
      "source": [
        "# 02 Enron Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGr-CkgPhPwP",
        "outputId": "2dbe8d04-14dd-4069-f926-b8edf35cf9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enron:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(1702, 1001) (1702, 53)\n",
            "Coverted into Dataframe\n",
            "(1702, 1001) (1702, 53)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x,y, _, _ = load_dataset('enron', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x.shape,y.shape)\n",
        "#change to matrix\n",
        "x2=x.todense()\n",
        "y2=y.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x2=pd.DataFrame(x2)\n",
        "y2=pd.DataFrame(y2)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x2.shape,y2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjjg_Ldi-x1x"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDYk2PBq-x1x"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x2, y2, K=int((x2.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x2.columns):\n",
        "    if i not in selected_features:\n",
        "        x2 = x2.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrE8vPVg-x1y",
        "outputId": "54d578f4-9b33-4705-f75b-aadf97844f3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1702, 618)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geaCWnlShd8V"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy72vS1uhdbF",
        "outputId": "aa75d568-623e-429d-c023-e6746f3e8200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1184, 618) (518, 618) (1184, 53) (518, 53)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x2 = s.csr_matrix(x2)\n",
        "y2 = s.csr_matrix(y2)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x2_train, y2_train, x2_test, y2_test = iterative_train_test_split(x2, y2, test_size = 0.3)\n",
        "print(x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UkG4qIhmA0"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQrV6hoHhnOl"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x2_train, y2_train)\n",
        "# predict\n",
        "MLTSVM2_predictions = classifier1.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4mQhAYhnu4"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9MCgnWXho55"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for enron dataset it has 53 labels.\n",
        "classifier2 = MLkNN(k=53)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x2_train, y2_train)\n",
        "\n",
        "# predict\n",
        "MLKNN2_predictions = classifier2.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q77FQROhquS"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd-XcJd3hrtL"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=53)\n",
        "# train\n",
        "classifier3.fit(x2_train, y2_train)\n",
        "# predict\n",
        "BR2_predictions = classifier3.predict(x2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s0jw9zchuXy"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRnvbkdhw6l"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0inwYSohyl9",
        "outputId": "f7928fe3-d0d3-4a77-d5b5-054320ef4722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels)\n",
            "------------------------------\n",
            "MLTSVM ->  (518, 53)\n",
            "MLKNN  ->  (518, 53)\n",
            "BRKNNa ->  (518, 53)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.08\n",
            "MLKNN  ->  0.06\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.02\n",
            "MLKNN  ->  0.06\n",
            "BRKNNa ->  0.06\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.39\n",
            "MLKNN ->  0.58\n",
            "BRKNNa ->  0.5\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  0.45\n",
            "MLTSVM ->  0.31\n",
            "MLTSVM ->  0.1\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.42\n",
            "MLTSVM ->  0.4\n",
            "MLTSVM ->  0.17\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels)\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM2_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN2_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR2_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y2_test, MLTSVM2_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y2_test, MLKNN2_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y2_test, BR2_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y2_test, MLTSVM2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y2_test, MLKNN2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y2_test, BR2_predictions, average='micro', zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLTSVM2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, MLKNN2_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y2_test, BR2_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2TXIFdh_nM"
      },
      "source": [
        "# 03 Scene Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMyBY_axh0sv",
        "outputId": "bc85eecc-5be7-478c-9b6d-e1e9d01e5ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scene:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(2407, 294) (2407, 6)\n",
            "Coverted into Dataframe\n",
            "(2407, 294) (2407, 6)\n"
          ]
        }
      ],
      "source": [
        "#from skmultilearn.dataset import load_dataset\n",
        "x3,y3, _, _ = load_dataset('scene', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x3.shape,y3.shape)\n",
        "#change to matrix\n",
        "x3=x3.todense()\n",
        "y3=y3.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x3=pd.DataFrame(x3)\n",
        "y3=pd.DataFrame(y3)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x3.shape,y3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgTMPlC_-x12"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqOqXjfB-x12"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x3, y3, K=int((x3.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x3.columns):\n",
        "    if i not in selected_features:\n",
        "        x3 = x3.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqqt8xWg-x12",
        "outputId": "44efd3f2-1040-4b6e-fa44-7cdbc5139c55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2407, 247)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5196nOiRQy"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y164N9r1iUqs",
        "outputId": "c2c3bcea-1086-4b2a-b9db-4781aa19cc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1685, 247) (722, 247) (1685, 6) (722, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x3 = s.csr_matrix(x3)\n",
        "y3 = s.csr_matrix(y3)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x3_train, y3_train, x3_test, y3_test = iterative_train_test_split(x3, y3, test_size = 0.3)\n",
        "print(x3_train.shape, x3_test.shape, y3_train.shape, y3_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7i-TEOYibPk"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spSuhLrwiclk"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x3_train, y3_train)\n",
        "# predict\n",
        "MLTSVM3_predictions = classifier1.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDkyhEm-idLA"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEOsqkozieMm"
      },
      "outputs": [],
      "source": [
        "#from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "# apply MLkNN for Scene dataset it has 6 labels.\n",
        "classifier2 = MLkNN(k=6)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x3_train, y3_train)\n",
        "\n",
        "# predict\n",
        "MLKNN3_predictions = classifier2.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soP4rbVxigYH"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8A69ylpiiIz"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=6)\n",
        "# train\n",
        "classifier3.fit(x3_train, y3_train)\n",
        "# predict\n",
        "BR3_predictions = classifier3.predict(x3_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8aWlmPiksm"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHQe8f4SinpS"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y3_test, MLKNN3_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y3_test, BR3_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAbuGy2aiqRN",
        "outputId": "723d2977-09ab-44e7-91b1-0e92500f57cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (722, 6)\n",
            "MLKNN  ->  (722, 6)\n",
            "BRKNNa ->  (722, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.7\n",
            "MLKNN  ->  0.09\n",
            "BRKNNa ->  0.1\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.64\n",
            "BRKNNa ->  0.58\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.2\n",
            "MLKNN ->  0.77\n",
            "BRKNNa ->  0.83\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.7\n",
            "BRKNNa ->  0.58\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.34\n",
            "MLKNN ->  0.73\n",
            "BRKNNa ->  0.69\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM3_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN3_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR3_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y3_test, BR3_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y3_test, MLTSVM3_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y3_test, MLKNN3_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y3_test, BR3_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.precision_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y3_test, MLTSVM3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y3_test, MLKNN3_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y3_test, BR3_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sT6Vlat-x15"
      },
      "source": [
        "# 04 Emotions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUyxEcVD-x16",
        "outputId": "48ad4872-e7d3-4edd-e45a-2370003d8fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emotions:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(593, 72) (593, 6)\n",
            "Coverted into Dataframe\n",
            "(593, 72) (593, 6)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x4,y4, _, _ = load_dataset('emotions', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x4.shape,y4.shape)\n",
        "#change to matrix\n",
        "x4=x4.todense()\n",
        "y4=y4.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x4=pd.DataFrame(x4)\n",
        "y4=pd.DataFrame(y4)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x4.shape,y4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeFAucJj-x16"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjoJBTCv-x16"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x4, y4, K=int((x4.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x4.columns):\n",
        "    if i not in selected_features:\n",
        "        x4 = x4.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4IX2WPU-x16",
        "outputId": "6d43399d-7dc2-44f0-dd87-b17263cf8f12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(593, 59)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjYYSO8jGMe"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqplGSrwjNaw",
        "outputId": "b3432efb-2369-4af5-e3a0-b08ac09ed983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(416, 59) (177, 59) (416, 6) (177, 6)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x4 = s.csr_matrix(x4)\n",
        "y4 = s.csr_matrix(y4)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x4_train, y4_train, x4_test, y4_test = iterative_train_test_split(x4, y4, test_size = 0.3)\n",
        "print(x4_train.shape, x4_test.shape, y4_train.shape, y4_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-uX-BIqjSMZ"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XklOJNDOjTVt"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x4_train, y4_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgzlva3xjT5y"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7SIU5KbjUyx"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x4_train, y4_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Yn9qcojXzz"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiUFTXdWjYxj"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x4_train, y4_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x4_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsQqXNfjbkI"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPZ71xjZjeBE"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y4_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y4_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ1wjsf7jgGo",
        "outputId": "ec2bdc3c-6f8b-4828-d1ac-2669135cf20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "\t(Examples,Labels\n",
            "------------------------------\n",
            "MLTSVM ->  (177, 6)\n",
            "MLKNN  ->  (177, 6)\n",
            "BRKNNa ->  (177, 6)\n",
            "------------------------------\n",
            "\tHamming Loss\n",
            "------------------------------\n",
            "MLTSVM ->  0.68\n",
            "MLKNN  ->  0.27\n",
            "BRKNNa ->  0.26\n",
            "------------------------------\n",
            "\tAccuracy\n",
            "------------------------------\n",
            "MLTSVM ->  0.0\n",
            "MLKNN  ->  0.08\n",
            "BRKNNa ->  0.1\n",
            "------------------------------\n",
            "\tPrecision\n",
            "------------------------------\n",
            "MLTSVM ->  0.32\n",
            "MLKNN ->  0.64\n",
            "MLKNNa ->  0.71\n",
            "------------------------------\n",
            "\tRecall\n",
            "------------------------------\n",
            "MLTSVM ->  1.0\n",
            "MLKNN ->  0.33\n",
            "BRKNNa ->  0.29\n",
            "------------------------------\n",
            "\tF1-measure\n",
            "------------------------------\n",
            "MLTSVM ->  0.48\n",
            "MLKNN ->  0.43\n",
            "BRKNNa ->  0.41\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y4_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y4_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y4_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y4_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y4_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y4_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f_yd4hsisv3"
      },
      "source": [
        "# 05 Genbase Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irsKBHGqi5gK",
        "outputId": "6f273469-d301-4fff-be18-d301b0bd83dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "genbase:undivided - exists, not redownloading\n",
            "Actual Dataset\n",
            "(662, 1186) (662, 27)\n",
            "Coverted into Dataframe\n",
            "(662, 1186) (662, 27)\n"
          ]
        }
      ],
      "source": [
        "from skmultilearn.dataset import load_dataset\n",
        "x5,y5, _, _ = load_dataset('genbase', 'undivided')\n",
        "print(\"Actual Dataset\")\n",
        "print(x5.shape,y5.shape)\n",
        "#change to matrix\n",
        "x5=x5.todense()\n",
        "y5=y5.todense()\n",
        "import pandas as pd\n",
        "#change to dataFrame\n",
        "x5=pd.DataFrame(x5)\n",
        "y5=pd.DataFrame(y5)\n",
        "print(\"Coverted into Dataframe\")\n",
        "print(x5.shape,y5.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAEZBDIW-x1_"
      },
      "source": [
        "## Feature Selection - Fisher Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzkEOr6g-x1_"
      },
      "outputs": [],
      "source": [
        "#call funtion\n",
        "# Usage example\n",
        "selected_features = select_features(x5, y5, K=int((x5.shape[1])*0.8),p=0.8)\n",
        "# print(\"Selected features based on Fisher's score:\", selected_features)\n",
        "#updated the original x\n",
        "for i in list(x5.columns):\n",
        "    if i not in selected_features:\n",
        "        x5 = x5.drop(columns=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTX9NimX-x1_",
        "outputId": "22721a36-116f-47f9-fab8-32da9626f229"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(662, 948)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ1R4dBv-x2A"
      },
      "source": [
        "## MLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3432efb-2369-4af5-e3a0-b08ac09ed983",
        "id": "MZkcSLnT-x2A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(463, 948) (199, 948) (463, 27) (199, 27)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse as s\n",
        "x5 = s.csr_matrix(x5)\n",
        "y5 = s.csr_matrix(y5)\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "x5_train, y5_train, x5_test, y5_test = iterative_train_test_split(x5, y5, test_size = 0.3)\n",
        "print(x5_train.shape, x5_test.shape, y5_train.shape, y5_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhyvYgBt-x2A"
      },
      "source": [
        "### MLTSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv8wIo3z-x2B"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLTSVM\n",
        "classifier1 = MLTSVM(c_k =2**-6)\n",
        "# train\n",
        "classifier1.fit(x5_train, y5_train)\n",
        "# predict\n",
        "MLTSVM5_predictions = classifier1.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27eVQpA-x2B"
      },
      "source": [
        "### MLKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TTpSz8T-x2B"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "#MLKNN is an adaptation of the kNN lazy learning algorithm for multi-label data.\n",
        "\n",
        "# apply MLkNN for delicious dataset it has 983 labels.\n",
        "classifier2 = MLkNN(k=27)\n",
        "\n",
        "# train\n",
        "classifier2.fit(x5_train, y5_train)\n",
        "\n",
        "# predict\n",
        "MLKNN5_predictions = classifier2.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSh7NaIV-x2B"
      },
      "source": [
        "### BRKNNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R84pCBCC-x2C"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.adapt import BRkNNaClassifier\n",
        "classifier3 = BRkNNaClassifier(k=27)\n",
        "# train\n",
        "classifier3.fit(x5_train, y5_train)\n",
        "# predict\n",
        "BR5_predictions = classifier3.predict(x5_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr4IUsbF-x2C"
      },
      "source": [
        "## Measuring Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyhhBEqq-x2C"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as m\n",
        "#Hamming Loss\n",
        "hamming_loss_MLTSVM.append(round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "hamming_loss_MLKNN.append(round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "hamming_loss_BRKNNa.append(round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Accuracy\n",
        "accuracy_MLTSVM.append(round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "accuracy_MLKNN.append(round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "accuracy_BRKNNa.append(round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "\n",
        "#Micro Precision\n",
        "precision_MLTSVM.append(round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_MLKNN.append(round(m.precision_score(y5_test, MLKNN5_predictions, average='micro', zero_division='warn'),2))\n",
        "precision_BRKNNa.append(round(m.precision_score(y5_test, BR5_predictions, average='micro', zero_division='warn'),2))\n",
        "\n",
        "#Micro Recall\n",
        "recall_MLTSVM.append(round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_MLKNN.append(round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "recall_BRKNNa.append(round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "#Micro F1 measure\n",
        "f1_measure_MLTSVM.append(round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_MLKNN.append(round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "f1_measure_BRKNNa.append(round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Rx7Bt1a-x2C"
      },
      "outputs": [],
      "source": [
        "print(\"------------------------------\")\n",
        "print(\"\\t(Examples,Labels\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",MLTSVM5_predictions.shape)\n",
        "print(\"MLKNN  -> \",MLKNN5_predictions.shape)\n",
        "print(\"BRKNNa -> \",BR5_predictions.shape)\n",
        "import sklearn.metrics as m\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tHamming Loss\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.hamming_loss(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.hamming_loss(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.hamming_loss(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tAccuracy\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.accuracy_score(y5_test, MLTSVM5_predictions),2))\n",
        "print(\"MLKNN  -> \",round(m.accuracy_score(y5_test, MLKNN5_predictions),2))\n",
        "print(\"BRKNNa -> \",round(m.accuracy_score(y5_test, BR5_predictions),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tPrecision\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.precision_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.precision_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNNa -> \",round(m.precision_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tRecall\")\n",
        "print(\"------------------------------\")\n",
        "print(\"MLTSVM -> \",round(m.recall_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.recall_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.recall_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"------------------------------\")\n",
        "print(\"\\tF1-measure\")\n",
        "print(\"------------------------------\")\n",
        "#f1=2*(p*r)/(p+r)\n",
        "print(\"MLTSVM -> \",round(m.f1_score(y5_test, MLTSVM5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"MLKNN -> \",round(m.f1_score(y5_test, MLKNN5_predictions, average='micro',zero_division='warn'),2))\n",
        "print(\"BRKNNa -> \",round(m.f1_score(y5_test, BR5_predictions, average='micro',zero_division='warn'),2))\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}